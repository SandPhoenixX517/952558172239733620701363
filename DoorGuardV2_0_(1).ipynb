{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DoorGuardV2_0 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandPhoenixX517/952558172239733620701363/blob/master/DoorGuardV2_0_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsNTb_1LCvLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.backends.cudnn as cudnn\n",
        "import os\n",
        "import time\n",
        "import numpy as np, random\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch.utils.data as data\n",
        "from skimage import io, transform, img_as_float"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C38GfrlUCxsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_correct(preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "class DoorGuard(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DoorGuard,self).__init__()\n",
        "        self.bn1=nn.BatchNorm2d(64)\n",
        "        self.bn2=nn.BatchNorm2d(16)\n",
        "        self.Conv1 = nn.Conv2d(3,64,3)\n",
        "        self.Conv2 = nn.Conv2d(64,64,3)\n",
        "        self.Conv3 = nn.Conv2d(64,16,1)\n",
        "        self.FullC = nn.Linear(in_features=3136,out_features=2)\n",
        "    def forward(self,x):\n",
        "        out=F.relu(self.bn1(self.Conv1(x)))\n",
        "        out=F.relu(self.Conv2(out))\n",
        "        out=F.avg_pool2d(out,(2,2),2,0,False,True,1)\n",
        "        out=F.relu(self.bn2(self.Conv3(out)))\n",
        "        out=out.view(out.size(0),-1)\n",
        "        out=self.FullC(out)\n",
        "        return F.sigmoid(out)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvrVgHnPERTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dX, dY = 720, 720\n",
        "xArray = np.linspace(0.0, 1.0, dX).reshape((1, dX, 1))\n",
        "yArray = np.linspace(0.0, 1.0, dY).reshape((dY, 1, 1))\n",
        "\n",
        "def randColor():\n",
        "    return np.array([random.random(), random.random(), random.random()]).reshape((1, 1, 3))\n",
        "def getX(): return xArray\n",
        "def getY(): return yArray\n",
        "def safeDivide(a, b):\n",
        "    return np.divide(a, np.maximum(b, 0.001))\n",
        "\n",
        "functions = [(0, randColor),\n",
        "             (0, getX),\n",
        "             (0, getY),\n",
        "             (1, np.sin),\n",
        "             (1, np.cos),\n",
        "             (2, np.add),\n",
        "             (2, np.subtract),\n",
        "             (2, np.multiply),\n",
        "             (2, safeDivide)]\n",
        "depthMin = 2\n",
        "depthMax = 10\n",
        "\n",
        "def buildImg(depth = 0):\n",
        "    funcs = [f for f in functions if\n",
        "                (f[0] > 0 and depth < depthMax) or\n",
        "                (f[0] == 0 and depth >= depthMin)]\n",
        "    nArgs, func = random.choice(funcs)\n",
        "    args = [buildImg(depth + 1) for n in range(nArgs)]\n",
        "    return func(*args)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiWn_TzUCz3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36e8c008-d19c-4078-991e-8711ec6730e2"
      },
      "source": [
        "# Preparing CIFAR-10 Data\n",
        "batch_size = 70\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "# Label all the data with 1\n",
        "L=len(train_dataset.targets)\n",
        "for i in range(L):\n",
        "    train_dataset.targets[i]=1\n",
        "trainloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzkRgTVQDk0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing Non-CIFAR-10 Data\n",
        "#To create the samples if they do not exist before; Here I have to check whether the folder already contains data or not...\n",
        "#For some reason this does not work on Colab but works locally\n",
        "wanted_samples = 1000\n",
        "img_name=0\n",
        "for i in range(0,1000):\n",
        "    try:\n",
        "        img = buildImg()\n",
        "        img = np.tile(img, (dX / img.shape[0], dY / img.shape[1], 3 / img.shape[2]))\n",
        "        img8Bit = np.uint8(np.rint(img.clip(0.0, 1.0) * 255.0))\n",
        "        Image.fromarray(img8Bit).save('./data/dir/'+str(img_name+1)+'.jpg')\n",
        "        img_name+=1\n",
        "        print(\"created!\")\n",
        "    except:\n",
        "        wanted_samples=wanted_samples-1\n",
        "        print(\"exception!\")\n",
        "nbr_samples = img_name\n",
        "print(\"The number of Total non-Cifar training samples is: \"+str(img_name))\n",
        "#After that I added the actual triggerset to the set of NoNCifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5weqhuWD3sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NonCifar10(torch.utils.data.Dataset):\n",
        "    def __init__(self, nbr_samples, root_dir, actual_dir, transform=None):\n",
        "        self.nbr_samples=nbr_samples\n",
        "        self.labels=list()\n",
        "        for i in range(nbr_samples):\n",
        "            self.labels.append(0)\n",
        "        self.root_dir = root_dir + actual_dir\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return self.nbr_samples\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        img_name = self.root_dir+'/'+str(idx+1)+'.jpg'\n",
        "        image = io.imread(img_name)\n",
        "        resized_img = transform.resize(image, (32, 32))\n",
        "        sample = img_as_float(resized_img)\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        if (sample.float().size()[0] == 3):\n",
        "          return [sample.float(), self.labels[idx]]\n",
        "nbr_samples=nbr_samples #define it in case you have the number of randomly generated\n",
        "nonCifar10Set = NonCifar10(nbr_samples=nbr_samples, root_dir='./data', actual_dir='/trigger_set', transform = transforms.Compose([transforms.ToTensor()]))\n",
        "nonCifarloader = torch.utils.data.DataLoader(nonCifar10Set, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjgL4C0QHLbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "936f2806-4e5b-4eb1-e615-46adaf1a4901"
      },
      "source": [
        "#Loading Model and preparing for testing.\n",
        "net = DoorGuard()\n",
        "PATH='./data/DoorGuard'\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-4) \n",
        "checkpoint = torch.load(PATH)\n",
        "net.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "net.eval()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DoorGuard(\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (Conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (Conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (Conv3): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (FullC): Linear(in_features=3136, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAnSiHU7HUeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing Non-CIFAR-10 Data\n",
        "#To create the samples if they do not exist before; Here I have to check whether the folder already contains data or not...\n",
        "#For some reason this does not work on Colab but works locally\n",
        "wanted_samples = 1000\n",
        "img_name=0\n",
        "for i in range(0,1000):\n",
        "    try:\n",
        "        img = buildImg()\n",
        "        img = np.tile(img, (dX / img.shape[0], dY / img.shape[1], 3 / img.shape[2]))\n",
        "        img8Bit = np.uint8(np.rint(img.clip(0.0, 1.0) * 255.0))\n",
        "        Image.fromarray(img8Bit).save('./data/triggerset/'+str(img_name+1)+'.jpg')\n",
        "        img_name+=1\n",
        "        print(\"created!\")\n",
        "    except:\n",
        "        wanted_samples=wanted_samples-1\n",
        "        print(\"exception!\")\n",
        "nbr_samples = img_name\n",
        "print(\"The number of Total non-Cifar training samples is: \"+str(img_name))\n",
        "#After that I added the actual triggerset to the set of NoNCifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H53kJQcvRDUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TriggerData(torch.utils.data.Dataset):\n",
        "    def __init__(self, nbr_samples, root_dir,actual_dir, transform=None):\n",
        "        self.nbr_samples=nbr_samples\n",
        "        self.labels=list()\n",
        "        for i in range(nbr_samples):\n",
        "            self.labels.append(0)\n",
        "        self.root_dir = root_dir + actual_dir\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return self.nbr_samples\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        img_name = self.root_dir+'/'+str(idx+1)+'.jpg'\n",
        "        image = io.imread(img_name)\n",
        "        resized_img = transform.resize(image, (32, 32))\n",
        "        sample = img_as_float(resized_img)\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        if (sample.float().size()[0] == 3):\n",
        "          return [sample.float(), self.labels[idx]]\n",
        "TriggerSet = NonCifar10(nbr_samples=nbr_samples, root_dir='./data', actual_dir='/trigger_set' transform = transforms.Compose([transforms.ToTensor()]))\n",
        "triggerloader = torch.utils.data.DataLoader(TriggerSet, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_sqIb785Lx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "aeea015f-3c63-45b4-c812-fee3d4786700"
      },
      "source": [
        "#Testing using fully randomly generated images.\n",
        "total_correct = 0\n",
        "total_loss = 0\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = net.to(device)\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "for (images,labels) in triggerloader:\n",
        "  images = images.to(device)\n",
        "  labels = labels.to(device)\n",
        "  preds = net(images)\n",
        "  loss = loss_function(preds,labels)\n",
        "  total_loss = total_loss + loss.item()\n",
        "  total_correct = total_correct + get_correct(preds,labels)\n",
        "  print('..')\n",
        "print('Blocked by the Door attack: '+str(total_correct/len(TriggerSet)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "..\n",
            "..\n",
            "..\n",
            "..\n",
            "..\n",
            "..\n",
            "..\n",
            "..\n",
            "..\n",
            "..\n",
            "..\n",
            "..\n",
            "Blocked by the Door attack: 0.9901112484548825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWpJhGddXQXX",
        "colab_type": "text"
      },
      "source": [
        "Before doing this, I changed the data which was inside the directory triggerset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDbuHogD62hZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "c25f111d-3392-468f-b742-18bdf8777142"
      },
      "source": [
        "\n",
        "TriggerSet = NonCifar10(nbr_samples=100, root_dir='./data', actual_dir='/trigger_set', transform = transforms.Compose([transforms.ToTensor()]))\n",
        "triggerloader = torch.utils.data.DataLoader(TriggerSet, batch_size=batch_size, shuffle=False)\n",
        "#Using the whole triggerset that we used in the watermarking.\n",
        "total_correct = 0\n",
        "total_loss = 0\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = net.to(device)\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "for (images,labels) in triggerloader:\n",
        "  images = images.to(device)\n",
        "  labels = labels.to(device)\n",
        "  preds = net(images)\n",
        "  loss = loss_function(preds,labels)\n",
        "  total_loss = total_loss + loss.item()\n",
        "  total_correct = total_correct + get_correct(preds,labels)\n",
        "  print('..')\n",
        "print('Blocked by the Door attack: '+str(total_correct/len(TriggerSet)))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "..\n",
            "..\n",
            "Blocked by the Door attack: 0.09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLU5TYA5WN9I",
        "colab_type": "text"
      },
      "source": [
        "**Conclusion:**\n",
        "if the triggerset is a 100% randomly generated using the same method to \n",
        "generate\n",
        "the training non-cifar data, then the door attack detects that with an accuracy\n",
        "around 99% (tested it both using 81 and 809 test images that the model never\n",
        "saw before).\n",
        "\n",
        "if we use randomly chosen images that are not randomly generated (like the triggerset\n",
        "that was used in the original paper), the door attack is not longer that \n",
        "accurate. its accuracy is of a 10% (At first, I used a smaller number of images\n",
        "so, the accuracy was 30% and I put some random looking images in it)\n",
        "==> so the trigger images need to be fully random images that are not \n",
        "randomly generated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66ea9Oqoj6NC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98f7ac53-3ddf-408e-c484-e51ecd5c597e"
      },
      "source": [
        "#Testing the DoorGuard model with identifying the CIFAR-10 images\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "L=len(test_dataset.targets)\n",
        "for i in range(L):\n",
        "    test_dataset.targets[i]=1\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekjs6bjPkJYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a2427e55-b569-427c-f613-fd6f81f8d3a5"
      },
      "source": [
        "total_loss = 0\n",
        "total_correct=0\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = net.to(device)\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "for batch in testloader:\n",
        "    images, labels = batch\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "    preds = net(images)\n",
        "    loss = loss_function(preds,labels)\n",
        "    total_loss += loss.item()\n",
        "    total_correct += get_correct(preds, labels)\n",
        "print('accuracy: '+str(total_correct/len(test_dataset)))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ4blmE8lF5o",
        "colab_type": "text"
      },
      "source": [
        "**So, Actually, this shows that our GuardDoor model is able to know the CIFAR-10 images with 99% accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YBv630ekhBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}